{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "ia.seed(1)\n",
    "# imgaug uses matplotlib backend for displaying images\n",
    "%matplotlib inline\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa \n",
    "# imageio library will be used for image input/output\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "# this library is needed to read XML files for converting it into CSV\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will extract column data for our CSV file as pandas DataFrame\n",
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            try:\n",
    "                value = (root.find('filename').text,\n",
    "                         int(root.find('size')[0].text),\n",
    "                         int(root.find('size')[1].text),\n",
    "                         int(member[4][0].text),\n",
    "                         int(member[4][1].text),\n",
    "                         int(member[4][2].text),\n",
    "                         int(member[4][3].text),\n",
    "                         member[0].text\n",
    "                         )\n",
    "                xml_list.append(value)\n",
    "            except:\n",
    "                pass\n",
    "    column_name = ['filename', 'width', 'height','xmin', 'ymin', 'xmax', 'ymax','class']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "   \n",
    "# apply the function to convert all XML files in images/ folder into labels.csv\n",
    "labels_df = xml_to_csv('../../images/AGRI_LEG_LAB')\n",
    "#labels_df = xml_to_csv('../../images/TRUE_LAB')\n",
    "labels_df.to_csv(('labels.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize\n",
    "height_resize = iaa.Sequential([ \n",
    "    iaa.Resize({\"height\": 1000, \"width\": 'keep-aspect-ratio'})\n",
    "])\n",
    "width_resize = iaa.Sequential([ \n",
    "    iaa.Resize({\"height\": 'keep-aspect-ratio', \"width\": 1000})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert BoundingBoxesOnImage object into DataFrame\n",
    "def bbs_obj_to_df(bbs_object):\n",
    "#     convert BoundingBoxesOnImage object into array\n",
    "    bbs_array = bbs_object.to_xyxy_array()\n",
    "#     convert array into a DataFrame ['xmin', 'ymin', 'xmax', 'ymax'] columns\n",
    "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
    "    return df_bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgaug(df, images_path, aug_images_path, image_prefix):\n",
    "    # create data frame which we're going to populate with augmented image info\n",
    "    aug_bbs_xy = pd.DataFrame(columns=\n",
    "                              ['filename', 'width', 'height', 'xmin', 'ymin', 'xmax', 'ymax','class']\n",
    "                             )\n",
    "    grouped = df.groupby('filename')    \n",
    "    \n",
    "    for filename in df['filename'].unique():\n",
    "    #   Get separate data frame grouped by file name\n",
    "        group_df = grouped.get_group(filename)\n",
    "        group_df = group_df.reset_index()\n",
    "        group_df = group_df.drop(['index'], axis=1)\n",
    "        \n",
    "    #   The only difference between if and elif statements below is the use of height_resize and width_resize augmentors\n",
    "    #   deffined previously.\n",
    "\n",
    "    #   If image height is greater than or equal to image width \n",
    "    #   AND greater than 600px perform resizing augmentation shrinking image height to 600px.\n",
    "        if group_df['height'].unique()[0] >= group_df['width'].unique()[0] and group_df['height'].unique()[0] > 1000:\n",
    "        #   read the image\n",
    "            image = imageio.imread(images_path+filename)\n",
    "        #   get bounding boxes coordinates and write into array        \n",
    "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "        #   pass the array of bounding boxes coordinates to the imgaug library\n",
    "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
    "        #   apply augmentation on image and on the bounding boxes\n",
    "            image_aug, bbs_aug = height_resize(image=image, bounding_boxes=bbs)\n",
    "        #   write augmented image to a file\n",
    "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
    "        #   create a data frame with augmented values of image width and height\n",
    "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
    "            for index, _ in info_df.iterrows():\n",
    "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
    "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
    "        #   rename filenames by adding the predifined prefix\n",
    "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
    "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
    "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
    "        #   concat all new augmented info into new data frame\n",
    "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
    "        #   append rows to aug_bbs_xy data frame\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
    "            \n",
    "    #   if image width is greater than image height \n",
    "    #   AND greater than 600px perform resizing augmentation shrinking image width to 600px\n",
    "        elif group_df['width'].unique()[0] > group_df['height'].unique()[0] and group_df['width'].unique()[0] > 1000:\n",
    "        #   read the image\n",
    "            image = imageio.imread(images_path+filename)\n",
    "        #   get bounding boxes coordinates and write into array        \n",
    "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "        #   pass the array of bounding boxes coordinates to the imgaug library\n",
    "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
    "        #   apply augmentation on image and on the bounding boxes\n",
    "            image_aug, bbs_aug = width_resize(image=image, bounding_boxes=bbs)\n",
    "        #   write augmented image to a file\n",
    "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
    "        #   create a data frame with augmented values of image width and height\n",
    "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
    "            for index, _ in info_df.iterrows():\n",
    "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
    "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
    "        #   rename filenames by adding the predifined prefix\n",
    "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
    "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
    "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
    "        #   concat all new augmented info into new data frame\n",
    "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
    "        #   append rows to aug_bbs_xy data frame\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
    "\n",
    "    #     append image info without any changes if it's height and width are both less than 600px \n",
    "        else:\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, group_df])\n",
    "    # return dataframe with updated images and bounding boxes annotations \n",
    "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
    "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
    "    return aug_bbs_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images_df = resize_imgaug(labels_df, 'images/', 'images/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-56_16__-2_54_2020-09-06.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>323</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-56_16__-2_54_2020-09-06.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>869</td>\n",
       "      <td>1000</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-56_16__-2_58_2020-09-06.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>381</td>\n",
       "      <td>142</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-56_16__-2_58_2020-09-06.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>54</td>\n",
       "      <td>348</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-56_16__-2_58_2020-09-06.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>151</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-63_6__-9_96_2018-07-25.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>870</td>\n",
       "      <td>893</td>\n",
       "      <td>906</td>\n",
       "      <td>905</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-63_6__-9_96_2018-07-25.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>303</td>\n",
       "      <td>642</td>\n",
       "      <td>317</td>\n",
       "      <td>654</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>-63_6__-9_96_2018-07-25.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>221</td>\n",
       "      <td>526</td>\n",
       "      <td>232</td>\n",
       "      <td>540</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>-63_6__-9_96_2018-07-25.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>131</td>\n",
       "      <td>521</td>\n",
       "      <td>138</td>\n",
       "      <td>530</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>-63_6__-9_96_2018-07-25.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>223</td>\n",
       "      <td>297</td>\n",
       "      <td>262</td>\n",
       "      <td>331</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename width height xmin ymin xmax  ymax  class\n",
       "0    -56_16__-2_54_2020-09-06.jpg  1000   1000    1    1  219   323  legal\n",
       "1    -56_16__-2_54_2020-09-06.jpg  1000   1000    1  209  869  1000  legal\n",
       "2    -56_16__-2_58_2020-09-06.jpg  1000   1000   78    1  381   142  legal\n",
       "3    -56_16__-2_58_2020-09-06.jpg  1000   1000    1  185   54   348  legal\n",
       "4    -56_16__-2_58_2020-09-06.jpg  1000   1000    1   49   41   151  legal\n",
       "..                            ...   ...    ...  ...  ...  ...   ...    ...\n",
       "414   -63_6__-9_96_2018-07-25.jpg  1000   1000  870  893  906   905  legal\n",
       "415   -63_6__-9_96_2018-07-25.jpg  1000   1000  303  642  317   654  legal\n",
       "416   -63_6__-9_96_2018-07-25.jpg  1000   1000  221  526  232   540  legal\n",
       "417   -63_6__-9_96_2018-07-25.jpg  1000   1000  131  521  138   530  legal\n",
       "418   -63_6__-9_96_2018-07-25.jpg  1000   1000  223  297  262   331  legal\n",
       "\n",
       "[419 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.SomeOf(2, [    \n",
    "    iaa.Affine(scale=(0.5, 1.5)),\n",
    "    iaa.Affine(rotate=(-60, 60)),\n",
    "    #iaa.Affine(translate_percent={\"x\":(-0.3, 0.3),\"y\":(-0.3, 0.3)}),\n",
    "    iaa.Fliplr(1),\n",
    "    iaa.Multiply((0.5, 1.5)),\n",
    "    #iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
    "    #iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
    "    # create data frame which we're going to populate with augmented image info\n",
    "    aug_bbs_xy = pd.DataFrame(columns=\n",
    "                              ['filename', 'width', 'height','xmin' , 'ymin', 'xmax', 'ymax','class']\n",
    "                             )\n",
    "    grouped = df.groupby('filename')\n",
    "    \n",
    "    for filename in df['filename'].unique():\n",
    "    #   get separate data frame grouped by file name\n",
    "        group_df = grouped.get_group(filename)\n",
    "        group_df = group_df.reset_index()\n",
    "        group_df = group_df.drop(['index'], axis=1)   \n",
    "    #   read the image\n",
    "        image = imageio.imread(images_path+filename)\n",
    "    #   get bounding boxes coordinates and write into array        \n",
    "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "    #   pass the array of bounding boxes coordinates to the imgaug library\n",
    "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
    "        \n",
    "    #   apply augmentation on image and on the bounding boxes\n",
    "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
    "    #   disregard bounding boxes which have fallen out of image pane    \n",
    "        bbs_aug = bbs_aug.remove_out_of_image()\n",
    "    #   clip bounding boxes which are partially outside of image pane\n",
    "        bbs_aug = bbs_aug.clip_out_of_image()\n",
    "\n",
    "            \n",
    "    #   don't perform any actions with the image if there are no bounding boxes left in it    \n",
    "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
    "            pass\n",
    "        \n",
    "    #   otherwise continue\n",
    "        else:\n",
    "        #   write augmented image to a file\n",
    "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
    "        #   create a data frame with augmented values of image width and height\n",
    "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
    "            for index, _ in info_df.iterrows():\n",
    "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
    "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
    "        #   rename filenames by adding the predifined prefix\n",
    "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
    "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
    "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
    "        #   concat all new augmented info into new data frame\n",
    "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
    "        #   append rows to aug_bbs_xy data frame\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
    "    \n",
    "    # return dataframe with updated images and bounding boxes annotations \n",
    "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
    "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
    "    return aug_bbs_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images_df = image_aug(resized_images_df, 'images/', 'aug_images/', 'aug1_', aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              filename width height        xmin        ymin  \\\n",
      "0      aug1_-52_19-0_58_2019-09-24.jpg  1000   1000  799.715210    1.623033   \n",
      "1      aug1_-52_19-0_62_2019-09-24.jpg  1000   1000  119.827866  779.044800   \n",
      "2      aug1_-52_19-0_62_2019-09-24.jpg  1000   1000  349.523895  678.533875   \n",
      "3      aug1_-52_19-0_62_2019-09-24.jpg  1000   1000  239.057907  776.914795   \n",
      "4      aug1_-52_19-0_62_2019-09-24.jpg  1000   1000  617.377747  628.609558   \n",
      "...                                ...   ...    ...         ...         ...   \n",
      "2169  aug1_-73_82--3_91_2019-09-03.jpg  1000   1000  545.091919  658.686951   \n",
      "2170  aug1_-73_82--3_91_2019-09-03.jpg  1000   1000  782.376587  607.955933   \n",
      "2171  aug1_-73_82--3_91_2019-09-03.jpg  1000   1000  898.328369  538.729248   \n",
      "2172  aug1_-73_82--3_91_2019-09-03.jpg  1000   1000  268.310516  618.545959   \n",
      "2173  aug1_-73_82--3_91_2019-09-03.jpg  1000   1000  594.923584  999.624878   \n",
      "\n",
      "             xmax         ymax class  \n",
      "0      845.648560   114.159767  mine  \n",
      "1      225.769028   875.646362  mine  \n",
      "2      418.029236   741.820068  mine  \n",
      "3      320.886658   854.623169  mine  \n",
      "4      718.333008   721.873413  mine  \n",
      "...           ...          ...   ...  \n",
      "2169   912.800903  1000.000000  mine  \n",
      "2170   915.062866   726.508179  mine  \n",
      "2171  1000.000000   678.001404  mine  \n",
      "2172   671.143005   955.624817  mine  \n",
      "2173   731.581787  1000.000000  mine  \n",
      "\n",
      "[2174 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(augmented_images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              filename  width  height        xmin        ymin  \\\n",
      "0      aug1_-52_19-0_58_2019-09-24.jpg   1000    1000  922.301880  379.163879   \n",
      "1      aug1_-52_19-0_62_2019-09-24.jpg   1000    1000    0.000000  571.196716   \n",
      "2      aug1_-52_19-0_62_2019-09-24.jpg   1000    1000  222.103165  604.498413   \n",
      "3      aug1_-52_19-0_62_2019-09-24.jpg   1000    1000   51.001396  632.058411   \n",
      "4      aug1_-52_19-0_62_2019-09-24.jpg   1000    1000  500.000000  742.298462   \n",
      "...                                ...    ...     ...         ...         ...   \n",
      "2161  aug1_-73_82--3_91_2019-09-03.jpg   1000    1000  734.355164   81.221779   \n",
      "2162  aug1_-73_82--3_91_2019-09-03.jpg   1000    1000  701.518127    0.000000   \n",
      "2163  aug1_-73_82--3_91_2019-09-03.jpg   1000    1000  586.077454  413.756470   \n",
      "2164  aug1_-73_82--3_91_2019-09-03.jpg   1000    1000    0.000000    0.000000   \n",
      "2165  aug1_-73_82--3_91_2019-09-03.jpg   1000    1000    0.000000    0.000000   \n",
      "\n",
      "             xmax        ymax class  \n",
      "0     1000.000000  476.619598  mine  \n",
      "1       30.331383  635.503418  mine  \n",
      "2      287.558197  648.135071  mine  \n",
      "3      125.643105  689.475098  mine  \n",
      "4      596.460083  806.605164  mine  \n",
      "...           ...         ...   ...  \n",
      "2161   891.308655  232.475647  mine  \n",
      "2162   870.367188   85.724068  mine  \n",
      "2163  1000.000000  854.342468  mine  \n",
      "2164     0.000000    0.000000  mine  \n",
      "2165     0.000000    0.000000  mine  \n",
      "\n",
      "[2166 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ea0e81b11aba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#df = df.xmin.astype(int)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmented_images_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m#print(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\labelimg\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5529\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5530\u001b[0m                     results.append(\n\u001b[1;32m-> 5531\u001b[1;33m                         \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5532\u001b[0m                     )\n\u001b[0;32m   5533\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\labelimg\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5544\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5545\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5546\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5547\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\labelimg\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\labelimg\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\labelimg\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\labelimg\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat\n",
    "all_labels_df = pd.concat([resized_images_df, augmented_images_df])\n",
    "all_labels_df.to_csv('all_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all images together\n",
    "for file in os.listdir('aug_images'):\n",
    "    shutil.copy('aug_images/'+file, 'imagesAndAug/'+file)\n",
    "for file in os.listdir('images'):\n",
    "    shutil.copy('images/'+file, 'imagesAndAug/'+file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelimg",
   "language": "python",
   "name": "labelimg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
